Data Science II: Homework 3
================

In this problem, you will develop a model to predict whether a given car
gets high or low gas mileage based on the dataset “auto.csv”. The
dataset contains 392 observations.

The response variable is “mpg cat”, which indicates whether the miles
per gallon of a car is high or low. The predictors include both
continuous and categorical variables:  
- **cylinders**: Number of cylinders between 4 and 8  
- **displacement**: Engine displacement (cu. inches)  
- **horsepower**: Engine horsepower  
- **weight**: Vehicle weight (lbs.)  
- **acceleration**: Time to accelerate from 0 to 60 mph (sec.)  
- **year**: Model year (modulo 100)  
- **origin**: Origin of car (1. American, 2. European, 3. Japanese) -
**mpg_cat**: *response variable* indicates whether the miles per gallon
of a car is ‘high’ or ‘low’

### Import Data

``` r
auto = read.csv("auto.csv")
head(auto)
```

    ##   cylinders displacement horsepower weight acceleration year origin mpg_cat
    ## 1         8          307        130   3504         12.0   70      1     low
    ## 2         8          350        165   3693         11.5   70      1     low
    ## 3         8          318        150   3436         11.0   70      1     low
    ## 4         8          304        150   3433         12.0   70      1     low
    ## 5         8          302        140   3449         10.5   70      1     low
    ## 6         8          429        198   4341         10.0   70      1     low

### Split the dataset into two parts: training data (70%) and test data (30%).

``` r
library(caret)
```

    ## Loading required package: ggplot2

    ## Loading required package: lattice

``` r
library(tidymodels)
```

    ## ── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──

    ## ✔ broom        1.0.7     ✔ rsample      1.2.1
    ## ✔ dials        1.4.0     ✔ tibble       3.2.1
    ## ✔ dplyr        1.1.4     ✔ tidyr        1.3.1
    ## ✔ infer        1.0.7     ✔ tune         1.3.0
    ## ✔ modeldata    1.4.0     ✔ workflows    1.2.0
    ## ✔ parsnip      1.3.0     ✔ workflowsets 1.1.0
    ## ✔ purrr        1.0.4     ✔ yardstick    1.3.2
    ## ✔ recipes      1.1.1

    ## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
    ## ✖ purrr::discard()         masks scales::discard()
    ## ✖ dplyr::filter()          masks stats::filter()
    ## ✖ dplyr::lag()             masks stats::lag()
    ## ✖ purrr::lift()            masks caret::lift()
    ## ✖ yardstick::precision()   masks caret::precision()
    ## ✖ yardstick::recall()      masks caret::recall()
    ## ✖ yardstick::sensitivity() masks caret::sensitivity()
    ## ✖ yardstick::specificity() masks caret::specificity()
    ## ✖ recipes::step()          masks stats::step()

``` r
datSplit <- initial_split(data = auto, prop = 0.7)
trainData <- training(datSplit)
testData <- testing(datSplit)
head(trainData)
```

    ##   cylinders displacement horsepower weight acceleration year origin mpg_cat
    ## 1         4          108         75   2350         16.8   81      3    high
    ## 2         8          304        120   3962         13.9   76      1     low
    ## 3         8          302        137   4042         14.5   73      1     low
    ## 4         4          120         87   2979         19.5   72      2     low
    ## 5         4          116         81   2220         16.9   76      2    high
    ## 6         4          121         98   2945         14.5   75      2     low

``` r
trainData$mpg_cat <- as.factor(trainData$mpg_cat)
testData$mpg_cat <- as.factor(testData$mpg_cat)
```

#### (a) Perform logistic regression analysis. Are there redundant predictors in your model? If so, identify them. If there are none, please provide an explanation.

Yes, there are redundant predictors in the model. By using the
Pr(\>\|z\|) in the logistic regression model, the following variables
are redundant: cylinders, displacement, horsepower, acceleration, and
origin. The predictors stated above have p-values \> 0.05 and therefore
do not contribute to the model in a statistically significant way.

##### Perform logistic regression analysis

``` r
set.seed(2)
glmnGrid = expand.grid(.alpha = seq(0, 1, length = 21),
.lambda = exp(seq(-8, -1, length = 50)))

ctrl = trainControl(method = "cv", number = 10,
summaryFunction = twoClassSummary,
classProbs = TRUE)

glm.fit = train(x = trainData[, c("cylinders", "displacement", "horsepower", 
                                  "weight", "acceleration", "year", "origin")],  
                y = trainData$mpg_cat, 
                   method = "glm",   
                   family = "binomial",  
                   metric = "ROC", 
                   trControl = ctrl)

summary(glm.fit)  
```

    ## 
    ## Call:
    ## NULL
    ## 
    ## Coefficients:
    ##               Estimate Std. Error z value Pr(>|z|)    
    ## (Intercept)  25.771393   8.134615   3.168  0.00153 ** 
    ## cylinders    -0.088535   0.488912  -0.181  0.85630    
    ## displacement -0.005948   0.014006  -0.425  0.67106    
    ## horsepower    0.011585   0.028079   0.413  0.67992    
    ## weight        0.006060   0.001530   3.960 7.49e-05 ***
    ## acceleration -0.139814   0.173867  -0.804  0.42131    
    ## year         -0.516774   0.106751  -4.841 1.29e-06 ***
    ## origin       -0.655701   0.461498  -1.421  0.15537    
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## (Dispersion parameter for binomial family taken to be 1)
    ## 
    ##     Null deviance: 379.83  on 273  degrees of freedom
    ## Residual deviance: 101.80  on 266  degrees of freedom
    ## AIC: 117.8
    ## 
    ## Number of Fisher Scoring iterations: 8

##### Adjusting logistic regression model to include only non-redundant predictors

``` r
glm.fit2 = train(x = trainData[c("weight", "year")],  
                 y = trainData$mpg_cat,  
                 method = "glm",   
                 family = "binomial",  
                 metric = "ROC",  
                 trControl = ctrl)  

summary(glm.fit2)
```

    ## 
    ## Call:
    ## NULL
    ## 
    ## Coefficients:
    ##               Estimate Std. Error z value Pr(>|z|)    
    ## (Intercept) 22.5666520  6.2284918   3.623 0.000291 ***
    ## weight       0.0056023  0.0007766   7.214 5.42e-13 ***
    ## year        -0.5055258  0.0981276  -5.152 2.58e-07 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## (Dispersion parameter for binomial family taken to be 1)
    ## 
    ##     Null deviance: 379.83  on 273  degrees of freedom
    ## Residual deviance: 105.82  on 271  degrees of freedom
    ## AIC: 111.82
    ## 
    ## Number of Fisher Scoring iterations: 7

#### (b) Train a multivariate adaptive regression spline (MARS) model. Does the MARS model improve prediction performance compared to logistic regression?

``` r
mars_grid <- expand.grid(degree = 1:2,
                         nprune = 2:4)

ctrl1 <- trainControl(method = "cv", number = 10)

trainData$mpg_cat <- as.factor(trainData$mpg_cat)

set.seed(2)

mars.fit <- train(x = trainData[, c("cylinders", "displacement", "horsepower", 
                                    "weight", "acceleration", "year", "origin")],  
                  y = trainData$mpg_cat,   
                 method = "earth",         
                 tuneGrid = mars_grid,     
                 trControl = ctrl1)        
```

    ## Loading required package: earth

    ## Loading required package: Formula

    ## Loading required package: plotmo

    ## Loading required package: plotrix

    ## 
    ## Attaching package: 'plotrix'

    ## The following object is masked from 'package:scales':
    ## 
    ##     rescale

``` r
ggplot(mars.fit)
```

![](HW3_JRM2319_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

##### Prediction performance of Logistic Regression

``` r
glm.pred = predict(glm.fit2, newdata = testData, type = "raw")
head(glm.pred)
```

    ## [1] low low low low low low
    ## Levels: high low

##### Prediction performance of MARS

``` r
mars.pred = predict(mars.fit, newdata = testData, type = "raw")
head(mars.pred)
```

    ## [1] low low low low low low
    ## Levels: high low

##### Model Performance Comparison

``` r
confusionMatrix(glm.pred, testData$mpg_cat)
```

    ## Confusion Matrix and Statistics
    ## 
    ##           Reference
    ## Prediction high low
    ##       high   54   9
    ##       low     6  49
    ##                                          
    ##                Accuracy : 0.8729         
    ##                  95% CI : (0.799, 0.9271)
    ##     No Information Rate : 0.5085         
    ##     P-Value [Acc > NIR] : <2e-16         
    ##                                          
    ##                   Kappa : 0.7455         
    ##                                          
    ##  Mcnemar's Test P-Value : 0.6056         
    ##                                          
    ##             Sensitivity : 0.9000         
    ##             Specificity : 0.8448         
    ##          Pos Pred Value : 0.8571         
    ##          Neg Pred Value : 0.8909         
    ##              Prevalence : 0.5085         
    ##          Detection Rate : 0.4576         
    ##    Detection Prevalence : 0.5339         
    ##       Balanced Accuracy : 0.8724         
    ##                                          
    ##        'Positive' Class : high           
    ## 

``` r
confusionMatrix(mars.pred, testData$mpg_cat)
```

    ## Confusion Matrix and Statistics
    ## 
    ##           Reference
    ## Prediction high low
    ##       high   56   8
    ##       low     4  50
    ##                                           
    ##                Accuracy : 0.8983          
    ##                  95% CI : (0.8291, 0.9463)
    ##     No Information Rate : 0.5085          
    ##     P-Value [Acc > NIR] : <2e-16          
    ##                                           
    ##                   Kappa : 0.7963          
    ##                                           
    ##  Mcnemar's Test P-Value : 0.3865          
    ##                                           
    ##             Sensitivity : 0.9333          
    ##             Specificity : 0.8621          
    ##          Pos Pred Value : 0.8750          
    ##          Neg Pred Value : 0.9259          
    ##              Prevalence : 0.5085          
    ##          Detection Rate : 0.4746          
    ##    Detection Prevalence : 0.5424          
    ##       Balanced Accuracy : 0.8977          
    ##                                           
    ##        'Positive' Class : high            
    ## 

The MARS model does not significantly improve prediction performance
compared to logistic regression. Both models achieve high accuracy
(92.37% for logistic regression vs. 91.53% for MARS). Logistic
regression has a slightly higher overall accuracy and specificity, while
MARS has a slightly better sensitivity, meaning it identifies
high-mileage cars more effectively.

However, the differences are minimal, and both models perform well.
Since there is no substantial improvement in predictive performance,
logistic regression may be preferable due to its interpretability and
simplicity.

#### (c) Perform linear discriminant analysis using the **training** data. Plot the linear discriminant(s)

#### (d) Which model will you choose to predict the response variable? Plot its ROC curve and report the AUC. Next, select a probability threshold to classify observations and compute the confusion matrix. Briefly interpret what the confusion matrix indicates about your model’s performance.
